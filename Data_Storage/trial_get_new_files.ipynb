{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from parsel import Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to extract the date from the file name\n",
    "def extract_date(filename):\n",
    "    try:\n",
    "        date_str = filename.split('.')[0].split('/')[1]\n",
    "        return datetime.strptime(date_str, \"%Y%m%d\")\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# Get the list of files in S3 and determine the most recent date\n",
    "def get_most_recent_date(s3_client, bucket_name, folder_name):\n",
    "    response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=folder_name)\n",
    "    files = response.get('Contents', [])\n",
    "    dates = []\n",
    "    for file in files:\n",
    "        filename = file['Key']\n",
    "        date = extract_date(filename)\n",
    "        if date:\n",
    "            dates.append(date)\n",
    "    return max(dates) if dates else datetime(1970, 1, 1)\n",
    "\n",
    "# Fetch new files from GDELT events page\n",
    "def fetch_new_files(start_date):\n",
    "    new_files = {'events': [], 'gkg': [], 'gkgcounts': []}    \n",
    "\n",
    "    events_url = \"http://data.gdeltproject.org/events/index.html\"\n",
    "    base = \"http://data.gdeltproject.org/events/\"\n",
    "    response = requests.get(events_url)\n",
    "    sel = Selector(text=response.text)\n",
    "    links = sel.xpath('//a/@href').extract()\n",
    "    \n",
    "    for link in links:\n",
    "        if link.endswith('.zip'):\n",
    "            date_str = link.split('.')[0]\n",
    "            try:\n",
    "                file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "                if file_date > start_date:\n",
    "                    new_files['events'].append(base + link)\n",
    "            except ValueError:\n",
    "                continue\n",
    "    \n",
    "    gkg_url = 'http://data.gdeltproject.org/gkg/index.html'    \n",
    "    base = \"http://data.gdeltproject.org/gkg/\"\n",
    "    response = requests.get(gkg_url)\n",
    "    sel = Selector(text=response.text)\n",
    "    links = sel.xpath('//a/@href').extract()   \n",
    "\n",
    "    for link in links:\n",
    "        if link.endswith('.zip'):\n",
    "            date_str = link.split('.')[0]\n",
    "            try:\n",
    "                file_date = datetime.strptime(date_str, \"%Y%m%d\")\n",
    "                if file_date > start_date:\n",
    "                    file_type = 'gkgcounts' if 'gkgcounts' in link else 'gkg'\n",
    "                    new_files[file_type].append(base + link)\n",
    "            except ValueError:\n",
    "                continue     \n",
    "\n",
    "    return new_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and upload new files\n",
    "def process_new_files(new_files, s3_client, bucket_name):\n",
    "    for file_type, links in new_files.items():\n",
    "        for link in links:\n",
    "            file_name = link.split('/')[-1]\n",
    "            response = requests.get(link)\n",
    "            file_content = io.BytesIO(response.content)\n",
    "            \n",
    "            with zipfile.ZipFile(file_content, 'r') as zip_ref:\n",
    "                for file_info in zip_ref.infolist():\n",
    "                    date = file_info.filename.split('.')[0]\n",
    "\n",
    "                    if file_type == 'events':\n",
    "                        folder_name = \"GDELT Event Files\"\n",
    "                        new_file_name = f\"{date}.csv\"\n",
    "                    if file_type == 'gkg':\n",
    "                        folder_name = \"GDELT GKG Files\"\n",
    "                        new_file_name = f\"{date}.{file_type}.csv\"\n",
    "                    if file_type == 'gkgcounts':\n",
    "                        folder_name = 'GDELT GKG Files/gkgcounts'\n",
    "                        new_file_name = f\"{date}.{file_type}.csv\"\n",
    "\n",
    "                    s3_key = folder_name + '/' + new_file_name\n",
    "                    \n",
    "                    with zip_ref.open(file_info) as extracted_file:\n",
    "                        s3_client.upload_fileobj(extracted_file, bucket_name, s3_key)\n",
    "                        print(f\"Uploaded {new_file_name} to S3 bucket {bucket_name} with key {s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS S3 Configuration\n",
    "credentials = pd.read_csv('../Data_Storage/isabelmorar_accessKeys.csv')\n",
    "access_key_id = credentials['Access key ID'][0]\n",
    "secret_access_key = credentials['Secret access key'][0]\n",
    "\n",
    "# AWS S3 Configuration\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id= access_key_id,        \n",
    "    aws_secret_access_key= secret_access_key,\n",
    "    region_name='us-east-1' \n",
    ")\n",
    "\n",
    "bucket_name = 'datathonfactored2024' \n",
    "folder_name = 'GDELT Event Files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GDELT Event Files/20240814.csv\n",
      "Uploaded 20240814.csv to S3 bucket datathonfactored2024 with key GDELT Event Files/20240814.csv\n",
      "GDELT GKG Files/20240814.gkg.csv\n",
      "Uploaded 20240814.gkg.csv to S3 bucket datathonfactored2024 with key GDELT GKG Files/20240814.gkg.csv\n",
      "GDELT GKG Files/gkgcounts/20240814.gkgcounts.csv\n",
      "Uploaded 20240814.gkgcounts.csv to S3 bucket datathonfactored2024 with key GDELT GKG Files/gkgcounts/20240814.gkgcounts.csv\n"
     ]
    }
   ],
   "source": [
    "start_date = get_most_recent_date(s3_client, bucket_name, folder_name)\n",
    "new_files = fetch_new_files(start_date)\n",
    "\n",
    "process_new_files(new_files, s3_client, bucket_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
