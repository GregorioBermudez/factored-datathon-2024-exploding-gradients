{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Dependencies"
      ],
      "metadata": {
        "id": "GN2zP0E1eE5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark\n",
        "!pip install -U -q PyDrive\n",
        "!apt update\n",
        "!apt install openjdk-8-jdk-headless -qq\n",
        "#!apt install default-jre\n",
        "#!apt install default-jdk\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrB0Z_7YVQTM",
        "outputId": "f3c95b6c-5bab-4eca-d862-067cbb79a083"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=c5780489fa8ab57bf79f8e49653460aad63b02b513cd0751dbb6a6b72d3d4f3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Ign:3 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,223 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,135 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,497 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,555 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,221 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [2,944 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [3,041 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,424 kB]\n",
            "Hit:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:19 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:20 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 24.4 MB in 3s (7,832 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "47 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "The following additional packages will be installed:\n",
            "  libxtst6 openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  openjdk-8-demo openjdk-8-source libnss-mdns fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic\n",
            "  fonts-ipafont-mincho fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  libxtst6 openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 3 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 39.6 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "(Reading database ... 123595 files and directories currently installed.)\n",
            "Preparing to unpack .../libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jre-headless_8u422-b05-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../openjdk-8-jdk-headless_8u422-b05-1~22.04_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u422-b05-1~22.04) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import string\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import CountVectorizer, IDF, Tokenizer\n",
        "from pyspark.ml.clustering import LDA\n",
        "\n",
        "# Data processing\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "A1IaMakvcTwt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text processing"
      ],
      "metadata": {
        "id": "iionBDCreLq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "punct = {'üíÅ', '[', '‚Äô', '~', 'üí™', 'üìö', 'üè°', '-', 'üê£', 'üá∫', '‚Äù', 'Ã∂', '\\u200a', ';', 'üçï', ' ', '!', '%', ',', 'üëá', '¬Æ', 'üåà', '?', 'üèΩ', '=', 'üí®', '‚úÖ', '‚úî', ')', '|', '‚Äò', '\\xa0', 'üóΩ', '&', 'üèº', '¬ø', '‚Ä¶', 'üéì', 'üëâ', '‚ùå', 'üéß', 'üëà', 'üöÇ', '+', 'ü§ñ', 'üëé', '‚Üí', '¬°', 'ü§î', 'Ô∏è', 'üë∏', '@', 'üá∏', ':', '‚Äú', '‚Ä¢', 'üèø', 'üèª', 'üëÄ', 'üëè', '‚Äî', ']', '‚úì', '\"', '\\u200b', 'üé§', '\\n', '.', '(', '$', '‚ù§', '‚¨á', '#', 'üëç', \"'\", '/', '*', 'üèæ', '‚Äì', 'üëø'}\n",
        "\n",
        "punct.remove(' ')  # keep spaces\n",
        "punct.remove('\\'') # keep single quotes (in order to retain I'm, isn't, etc.)\n",
        "\n",
        "def clean(text):\n",
        "    temp_text = text.lower()\n",
        "    temp_text = re.sub(r'https?://\\S+', '', temp_text)\n",
        "    temp_text = re.sub(r'\\d+', '0', temp_text)\n",
        "    temp_text = temp_text.replace('‚Äô', '\\'')  # some single quotes are slanted, and we want to retain them\n",
        "    for p in punct:\n",
        "        temp_text = temp_text.replace(p, ' ')\n",
        "    temp_text = re.sub(r'\\s+', ' ', temp_text)\n",
        "    cleaned_text = temp_text.strip()\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "id": "7nCSp6BFjJX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(text_vector, col_input , col_output):\n",
        "  tknzr = Tokenizer(inputCol=col_input, outputCol=col_output)\n",
        "  tokens=tknzr.transform(text_vector)\n",
        "  return tokens"
      ],
      "metadata": {
        "id": "Mlzglmw9jX7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train LDA model"
      ],
      "metadata": {
        "id": "S95LmgbKwVQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open dataframe with pandas\n",
        "data = pd.read_csv('Nombre_documento')\n",
        "data[\"cleaned\"] = data[\"description\"].apply(clean)\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"LDA\").getOrCreate()\n",
        "spark_df = spark.createDataFrame(data)\n",
        "\n",
        "# Tokenize the text\n",
        "words_data = tokenize(spark_df, \"cleaned\", \"key_words\")\n",
        "\n",
        "# Apply CountVectorizer to convert text to a vector of word counts\n",
        "vectorizer = CountVectorizer(inputCol=\"key_words\", outputCol=\"vectors\")\n",
        "cv_model = vectorizer.fit(words_data)\n",
        "count_vectors = cv_model.transform(words_data)\n",
        "\n",
        "# Train LDA model\n",
        "lda = LDA(k=3, maxIter=10, featuresCol=\"features\")\n",
        "lda_model = lda.fit(count_vectors)\n",
        "\n",
        "# Topic-Word Distributions\n",
        "topics = lda_model.describeTopics()\n",
        "print(\"Topics with their top-weighted words:\")\n",
        "topics.show(truncate=False)\n",
        "\n",
        "# Extracting top `k` most relevant words for each topic\n",
        "k = 5  # Set the number of top words you want for each topic\n",
        "vocab = cv_model.vocabulary  # Vocabulary learned by CountVectorizer\n",
        "\n",
        "topic_words_dict = {}\n",
        "for row in topics.collect():\n",
        "    topic_id = row['topic']\n",
        "    word_indices = row['termIndices'][:k]  # Get the indices of the top `k` words\n",
        "    topic_words = [vocab[index] for index in word_indices]  # Map indices to words\n",
        "    topic_words_dict[topic_id] = topic_words\n",
        "\n",
        "# Print the dictionary\n",
        "for topic, words in topic_words_dict.items():\n",
        "    print(f\"Topic {topic}: {', '.join(words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aAr-O1M3cleq",
        "outputId": "426acec9-54bc-406e-bdeb-a3d40a391eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Infer the topic distribution for each document\n",
        "document_topics = lda_model.transform(count_vectors)\n",
        "\n",
        "# Define a function to get the most likely topic\n",
        "def get_most_likely_topic(topic_distribution):\n",
        "    return int(topic_distribution.argmax())\n",
        "\n",
        "# Apply the function to extract the most likely topic\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "most_likely_topic_udf = udf(get_most_likely_topic, IntegerType())\n",
        "document_topics_with_id = document_topics.withColumn(\"most_likely_topic\", most_likely_topic_udf(document_topics[\"topicDistribution\"]))\n",
        "\n",
        "# Show the DataFrame with the new topic column\n",
        "document_topics_with_id.select(\"id\", \"most_likely_topic\").show(truncate=False)\n",
        "\n",
        "# If you want to convert this back to Pandas for further processing or saving:\n",
        "pandas_df_with_topics = document_topics_with_id.select(\"id\", \"most_likely_topic\").toPandas()\n",
        "\n",
        "# Join with original pandas DataFrame to add the topic column\n",
        "final_data = data.merge(pandas_df_with_topics, on='id')"
      ],
      "metadata": {
        "id": "0aRCD-qDymdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assign topic to new articles"
      ],
      "metadata": {
        "id": "_a-dT289wlMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Open the new dataframe with pandas\n",
        "new_data[\"cleaned\"] = new_data[\"description\"].apply(clean)\n",
        "\n",
        "# Convert the new data to a Spark DataFrame\n",
        "new_spark_df = spark.createDataFrame(new_data)\n",
        "\n",
        "# Tokenize the new text\n",
        "new_words_data = tokenize(new_spark_df, \"cleaned\", \"key_words\")\n",
        "\n",
        "# Transform the text into the same vector space using the trained CountVectorizer model\n",
        "new_count_vectors = cv_model.transform(new_words_data)\n",
        "\n",
        "# Use the trained LDA model to infer topics for the new article\n",
        "new_document_topic_distribution = lda_model.transform(new_count_vectors)\n",
        "\n",
        "# Show the topic distribution for the new article\n",
        "print(\"New Document-Topic Distribution:\")\n",
        "new_document_topic_distribution.select(\"id\", \"topicDistribution\").show(truncate=False)\n",
        "\n",
        "# Assuming you want to find the most likely topic\n",
        "topic_distribution = new_document_topic_distribution.select(\"topicDistribution\").collect()[0][\"topicDistribution\"]\n",
        "most_likely_topic = topic_distribution.argmax()\n",
        "\n",
        "print(f\"The new article is most likely about Topic {most_likely_topic}, which has the top words: {', '.join(topic_words_dict[most_likely_topic])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3nWipvZrhF1",
        "outputId": "ca90f9a2-59f6-4992-c160-81bb15f4e1b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic number: 0\n",
            "mensen 0.008319326916815514\n",
            "anderhalve 0.0062602265915572336\n",
            "elkaar 0.005896582071747818\n",
            "weer 0.0041825075002934675\n",
            "houd 0.004121815009317227\n",
            "gaan 0.0028879658252392282\n",
            "blijf 0.0027956829993769435\n",
            "moeten 0.0027135327847427207\n",
            "thuis 0.0026636756851713393\n",
            "alleen 0.002623671716643883\n",
            "iedereen 0.0026234541293194058\n",
            "buiten 0.0025252146255743475\n",
            "goed 0.0024155903307100713\n",
            "waar 0.002264940968694007\n",
            "corona 0.0021445912007319197\n",
            "Topic number: 1\n",
            "vanaf 0.00028354046761189814\n",
            "elkaar 0.000254256304623373\n",
            "miljoen 0.0002514556022981041\n",
            "maatschappij 0.0002496479282338025\n",
            "apart 0.0002460248185941758\n",
            "goed 0.00023863462194057008\n",
            "euro 0.00021877171869036244\n",
            "deelt 0.00021402801117738433\n",
            "vijf 0.00021016247253925847\n",
            "onderdrukt 0.0002076505284230324\n",
            "mits 0.00020756021660438232\n",
            "vrouw 0.00020705828805122345\n",
            "zien 0.00020604245333889163\n",
            "compensatie 0.00020293267794979677\n",
            "vervoerders 0.000201908703458855\n",
            "Topic number: 2\n",
            "anderhalve 0.0008817454351102398\n",
            "hond 0.0006011425200842562\n",
            "maurice 0.00045961621031054154\n",
            "#coronawet 0.0004131381106010083\n",
            "video 0.0003997167544218298\n",
            "wanneer 0.00039435000400329505\n",
            "punt 0.0003365083772704521\n",
            "alternatieve 0.00033357915843615344\n",
            "column 0.00032857601100780027\n",
            "gebleven 0.00032535715211224253\n",
            "gewoon 0.00031209934825119376\n",
            "wurgslang 0.0003078142577583619\n",
            "tijd 0.00030232797151248815\n",
            "sinds 0.00028834654894800417\n",
            "youtube 0.0002743113247307256\n",
            "Topic number: 3\n",
            "iedereen 0.00035181194962560357\n",
            "mooi 0.0002496742229669005\n",
            "klanten 0.0002397075274627459\n",
            "#spoedwet 0.0002218236592881596\n",
            "#beau 0.00022156244914353466\n",
            "supermarkt 0.0002163378729273574\n",
            "#malieveld 0.00021547231246657052\n",
            "#jensen 0.00021428855798035135\n",
            "#neetegenanderhalvemeter 0.00021280291172151277\n",
            "#corona 0.00020913691751964106\n",
            "flauwekul 0.00020889787212521782\n",
            "immunologie 0.0002073854390159917\n",
            "hoogleraar 0.00020500881075374814\n",
            "bedoelde 0.00020285097646084382\n",
            "stonden 0.0002019468430134867\n",
            "Topic number: 4\n",
            "weer 0.0010983913123900288\n",
            "normaal 0.000767133481337761\n",
            "nieuwe 0.0007365312761658029\n",
            "vochtigheid 0.0006940696334175215\n",
            "windvlaag 0.0006915216945683301\n",
            "regen 0.0006843206809870158\n",
            "wind 0.0006840750052283456\n",
            "temperatuur 0.0006839644737720236\n",
            "actueel 0.0006823468839201319\n",
            "#weathercloud 0.0006807668710909518\n",
            "luchtdruk 0.000674325628559703\n",
            "gaat 0.0006351188260119439\n",
            "samenleving 0.0005942460160944358\n",
            "index 0.0005667846256392404\n",
            "instraling 0.0005645253536338907\n",
            "Topic number: 5\n",
            "mensen 0.0009527979039766111\n",
            "dingen 0.0007580931889592008\n",
            "werkt 0.0006233150510380141\n",
            "gewoon 0.0006228671908112372\n",
            "anderhalvemeter 0.000614693762691542\n",
            "belangrijk 0.0005825770473984446\n",
            "mogen 0.0005804114348652927\n",
            "weer 0.0005608751942244404\n",
            "inmiddels 0.0005353730481165784\n",
            "economie 0.0005113700573422958\n",
            "mondkapjes 0.0004907971314363226\n",
            "gaat 0.0004708686308797682\n",
            "houd 0.0004530787407625133\n",
            "nemen 0.00044196660110051915\n",
            "twee 0.00043809716589824694\n",
            "Topic number: 6\n",
            "anderhalve 0.00043252257619487975\n",
            "werden 0.00040052034172290764\n",
            "onmogelijk 0.0003977193331708831\n",
            "even 0.0003800347358282418\n",
            "mensen 0.0003629977643487894\n",
            "#houdafstand 0.00035818318487993106\n",
            "regels 0.0003218202239482528\n",
            "moleculen 0.00028830955176445324\n",
            "ding 0.00028073474286053804\n",
            "verder 0.00027656624445828706\n",
            "microbiologie 0.00027269290204923316\n",
            "atomen 0.00027227916041793805\n",
            "cursus 0.0002687864661479416\n",
            "bedrog 0.0002677084127517477\n",
            "zaterdag 0.00026541880574422846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hwp7SOZBu3sG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}